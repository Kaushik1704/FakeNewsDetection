{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "import seaborn as sns\n",
        "from textblob import TextBlob  # For sentiment analysis\n",
        "from transformers import pipeline, AutoTokenizer  # HuggingFace transformers for BERT integration\n",
        "from tabulate import tabulate  # For beautifully formatted console outputs\n",
        "\n",
        "# Advanced Preprocessing Function\n",
        "def preprocess_text(df, column):\n",
        "    df[column] = df[column].str.lower()\n",
        "    df[column] = df[column].str.replace(r'[^\\w\\s]', '', regex=True)\n",
        "    df['text_length'] = df[column].apply(len)\n",
        "    df['sentiment'] = df[column].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "    return df\n",
        "\n",
        "# Load datasets\n",
        "true_data = pd.read_csv('True.csv')\n",
        "fake_data = pd.read_csv('Fake.csv')\n",
        "manual_testing_data = pd.read_csv('manual_testing.csv')\n",
        "\n",
        "# Add labels\n",
        "true_data['label'] = 1  # 1 = True\n",
        "fake_data['label'] = 0  # 0 = Fake\n",
        "\n",
        "# Combine datasets for training\n",
        "data = pd.concat([true_data, fake_data], axis=0).reset_index(drop=True)\n",
        "\n",
        "# Preprocess the data\n",
        "data = preprocess_text(data, 'text')\n",
        "manual_testing_data = preprocess_text(manual_testing_data, 'text')\n",
        "\n",
        "# Text Representation\n",
        "tfidf = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(data['text'])\n",
        "y_train = data['label']\n",
        "\n",
        "# Model Training (Random Forest)\n",
        "print(\"\\nüöÄ **Training the Random Forest model on True and Fake datasets...**\")\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "print(\"‚úÖ Random Forest model training complete!\")\n",
        "\n",
        "# Load BERT Model\n",
        "bert_classifier = pipeline(\"text-classification\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
        "\n",
        "# Truncate Text for BERT\n",
        "def truncate_text(text, max_length=512):\n",
        "    tokens = bert_tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        add_special_tokens=True  # Includes [CLS] and [SEP]\n",
        "    )\n",
        "    return bert_tokenizer.decode(tokens['input_ids'], skip_special_tokens=True)\n",
        "\n",
        "# Apply truncation\n",
        "manual_testing_data['truncated_text'] = manual_testing_data['text'].apply(lambda x: truncate_text(x, max_length=512))\n",
        "\n",
        "# Manual Testing\n",
        "print(\"\\nüìä **Evaluating manual testing dataset...**\")\n",
        "manual_tfidf = tfidf.transform(manual_testing_data['text'])\n",
        "manual_predictions = rf_model.predict(manual_tfidf)\n",
        "\n",
        "# Add Predictions to Manual Testing Data\n",
        "manual_testing_data['RF_Predicted Label'] = manual_predictions\n",
        "manual_testing_data['BERT_Predicted Sentiment'] = manual_testing_data['truncated_text'].apply(\n",
        "    lambda x: bert_classifier(x)[0]['label']\n",
        ")\n",
        "\n",
        "# Display Predictions in Tabular Form\n",
        "print(\"\\nüîç **Manual Testing Results:**\")\n",
        "results_table = tabulate(\n",
        "    manual_testing_data[['text', 'RF_Predicted Label', 'BERT_Predicted Sentiment']],\n",
        "    headers='keys',\n",
        "    tablefmt='grid',\n",
        "    maxcolwidths=[50, 20, 20]\n",
        ")\n",
        "print(results_table)\n",
        "\n",
        "# Check for Ground Truth in Manual Testing Data\n",
        "if 'label' in manual_testing_data.columns:\n",
        "    manual_testing_data['label'] = manual_testing_data['label'].map({0: 'Fake', 1: 'True'})\n",
        "    y_manual_test = manual_testing_data['label'].map({'Fake': 0, 'True': 1})\n",
        "    accuracy = accuracy_score(y_manual_test, manual_predictions)\n",
        "    print(f\"\\n‚ú® **Evaluation on Manual Testing Data:**\\nAccuracy: {accuracy:.2%}\")\n",
        "    print(\"\\nüîî **Classification Report:**\")\n",
        "    print(classification_report(y_manual_test, manual_predictions, target_names=['Fake', 'True']))\n",
        "\n",
        "    # AUC-ROC Curve\n",
        "    rf_probs = rf_model.predict_proba(manual_tfidf)[:, 1]\n",
        "    roc_auc = roc_auc_score(y_manual_test, rf_probs)\n",
        "    print(f\"AUC-ROC: {roc_auc:.2f}\")\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(y_manual_test, manual_predictions)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'True'], yticklabels=['Fake', 'True'])\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "# Visualizing Prediction Summary\n",
        "summary = manual_testing_data['RF_Predicted Label'].value_counts()\n",
        "summary_percentage = (summary / summary.sum()) * 100\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(x=summary.index, y=summary.values, palette='viridis')\n",
        "plt.title('Prediction Summary: True vs. Fake Articles')\n",
        "plt.xlabel('Article Type')\n",
        "plt.ylabel('Number of Articles')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Q12ctfEZp4us"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}